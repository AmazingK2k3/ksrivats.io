---
title: "The Disempowerment Dilemma: How Advanced AI Undermines the Foundations of Human Agency"
slug: "disempowerment-dilemma"
date: "2026-02-08"
tags: ["AI Safety", "AGI", "Society", "Economics", "Politics", "Human Agency"]
category: "AI & Society"
excerpt: "A critical examination of how advanced AI systems threaten to gradually erode human agency across economic, political, and cultural domains — and the open questions we must answer now."
featured: true
---
*This essay was written as part of the AI Safety, Ethics and Society course from Center for AI Safety — February 8th, 2026.*

---

> [!NOTE]
> If you are interested in reading this paper in a pdf version, [click here](https://drive.google.com/file/d/1k-OAZ6hxspTkFrVZQc-i5tmk6g6nk6ly/view?usp=sharing).

We are witnessing the beginning of the age of AI, a technology that is now deeply integrated within different aspects of society. People rely on them for daily decision-making [1], politicians rely on them for drafting their speeches [2], and consultancy firms rely on them to write policy reports [3]. Current estimates show that entry-level jobs are already being affected, with the rising unemployment rate indirectly linked to the rapid growth of technology [4]. Just in 2025, the number of claims for universal credit has skyrocketed to 8.3 million [5]. Big Tech has influenced stock markets and world governments, lobbying them to put all their eggs in AI-generated virtual baskets. Tech giants are selling a future of vast economic growth and a utopia of automation. In fact, OpenAI defines AGI (Artificial General Intelligence) as:

> "highly autonomous systems that outperform humans at most economically valuable work" [6]

But what does the future look like once AGI is achieved? As AIs become increasingly capable across various domains, would it actually lead towards a flourishing society catered towards human well-being? What if AGI brings disempowerment instead of empowerment? Would it lead to human beings gradually being displaced? Would humans lose control over critical institutions like the economy and eventually become disempowered?

When we think about catastrophic risks, it is clear that we tend to fall back on clear, distinct and immediate problem spaces — CBRN (Chemical, Biological, Radiological, Nuclear) and cybersecurity risks due to malicious use, rogue AI takeover scenarios, risks from AI Race, Concentration of Power, etc [7]. However, there is much less discussion on the risk of highly intelligent automation itself with respect to human agency or influence.

A future in which AGI gradually automates practically all work, resulting in enormous riches, means that potentially billions of people could lose their jobs. However, in addition to unemployment, unregulated technological advancement could eliminate the fundamental requirement for collective human participation in our institutions. Large-scale social organisations, such as governments and companies, may not have a motivation to care about people [8]. In such a culture, people would not only worry about their profession, but also their values, rights, agency, and overall meaning.

Is this even possible? How could a situation where AI replaces humans occur? What would it look like? **Part I of the investigation** will trace, using existing facts and examples, the steady erosion of human influence in different facets of society, resulting in the permanent disempowerment of humankind and irreversible loss of potential, creating an existential catastrophe. **Part II will follow**, with an emphasis on studying potential technological approaches to reduce the risk of erosion while assuring sustained human participation and resilience in our social infrastructure.

First, to understand how this risk plays out, let us first understand how our modern social systems, post the world wars, are broadly aligned towards human preferences and wellbeing.

---

## 1. The Social Contract

The modern economy is essentially driven by supply and demand for products and services. Human preferences play a significant role in demand. And human labour is a key part of the supply. The government taxes our earnings to support public services. Firms rely on human workers to create value, and in exchange, workers expect to be rewarded with opportunity and security. This is the broader social contract which evolved through the industrial age and the world wars spanning over the past two centuries [9].

However, during the Malthusian and feudal eras, land was the most significant factor of productivity. We only had marginal human labour to cultivate the land, which implies they did not produce excess economic value, giving rise to the well-known Malthusian Trap theory [10]. Power and institutions were mostly concerned with land. Land was the fundamental bottleneck for the economy.

That is, until the Industrial Revolution changed that. We created methods for producing goods such that land was no longer the fundamental constraint in the economy. Instead, we began creating things with machines, which we paired with labour. Capital + Labour = Output [11]. Technology began to increase steadily, so we built more and more machines; the accumulation of superior technologies led to economic growth. The bottleneck suddenly shifted to the human worker. Humans did not multiply at the same rate as technological advancement and capital; they became scarce. The scarcity of human work increased its economic value, boosting our living standards and quality of life.

Currently, modern states primarily rely on income taxes for revenue, which they obtain by raising citizen productivity. They rely on residents to provide labour for the economy and government, as well as to project authority through their military. The state is incentivised to generate highly educated professionals who will deliver a strong return on investment, so they invest in education, care about roads and infrastructure, establish legal and safe regulating systems, and ensure business formation. This is done to ensure their economic viability and geopolitical competitiveness with other countries. Governments and organisations theoretically exist to serve and rely on various human needs and values, extending even to governments rooted in autocratic orientations. Functioning of every kind of government involves human participation at every level, from bureaucracies to political representation to maintaining and interpreting the Law [12].

Even in the midst of the AI race, corporations continue to value talent. Workers have a skill set that businesses sorely need to increase their profits [13]. Workers continue to be in high demand. People utilise their economic power to intentionally shape the economy by boycotting companies, going on strike, purchasing products that reflect their views, and pursuing employment in specific areas and places. Employees have bargaining power, which allows them to demand expensive rewards, systemic rights, and improved quality of life.

All of them are diverse feedback loops that enforce an imperfect, broad social framework, ensuring that strong actors must accommodate people's implicit preferences and interests in order to achieve their goal of wealth creation or power acquisition. Ultimately, people's interactions with these enormous societal-scale systems based on their preferences yield outcomes that influence the future.

However, this is not a natural law. The example of rentier states [14], which rely on natural oil reserves for revenue rather than residents, demonstrates this. States can decrease the general public's participation in their operations while maintaining influence through the power of wealth distribution to preserve allegiance among essential stakeholders such as elites and the military [15]. The research and incentive structures of rentier states are beyond the scope of this paper, but consider this: if we assume and consider AI as a technological infrastructure beyond the scope of tools, comparable to oil and electricity, that is rapidly scaled with the intention of automating most work, it has the potential to fundamentally disrupt the broader social contract.

We have already seen enormous investment by actors in obtaining AGI. AI is clearly the most heavily invested technology in the last decade, with $1.6 trillion invested [16], as well as the most rapidly adopted in the world [17]. These measurements are driven by a variety of incentives, including competition at various levels, the prospect of future affluence and wealth, and so on, but they can be linked principally to the promise of intelligent automation [18]. Investments in AI aim to eliminate the specific bottleneck of economic growth that has been present since the Industrial Revolution — the broadly inelastic human labour, as pointed out earlier. This is done by automating intelligence and transferring the bottleneck to energy and resources [19].

In the AGI era, technology will speed up dramatically, capital will be reproduced, and labour will become abundant through machines for the first time in history. This might result in record growth, but there is no longer a systematic motivation to invest in people's long-term productivity. A hypothetical future with enormous capital growth, but disempowered people. Let's look at how we might get there in the future via the lenses of economy, politics, and society.

---

## 2. Progressing towards the Age of AGI — Intelligence Explosion and Curse

What happens if we eliminate the bottleneck of human labour? The majority of studies suggest a highly realistic intelligence explosion. A growth takeoff scenario occurs when we empower machines to undertake all valuable functions in the economy, causing the economy to grow at unprecedented rates. Imagine a century's worth of technological advancement and economic growth in just a few years. The fundamental part of the intelligence explosion is AI's ability to do research in order to advance itself and society as a whole. It would imply, for example, medical advances that significantly extend our life spans, as well as an abundance-oriented society. The important part of such an intelligence explosion is the eventual replacement of human labour with AI. AI labour rises due to two factors: improving software quality and improving hardware quality through accumulation (for example, robots and bot factories). This enhances economic productivity and output [20].

How would AGI result in leaving ordinary people behind? This may not be a dramatic, instantaneous event, but rather something more gradual and systemic. As demonstrated earlier, AGI could impact labour, politics, and society, but not in the ways you think:

### Labour and the Economy

Luke Drago and Rudolf Laine's essay, "The Intelligence Curse" presents an excellent vision of how AI might eventually automate the entire corporate pyramid structure, beginning with white-collar entry-level jobs [21]. Similar warnings have been issued by Nobel Prize-winning economist Daren Acemoglu and other notable members of industry and academia [22]. How much of this is truly reflected in data? Yes, the unemployment rate in the United States, for example, has increased from 3.5% to 4.3% in 2025, and this has been the general pattern around the world [23]. An early 2025 study found that AI had an influence on jobs, but only in particular areas, and that less experienced workers suffer the most [24]. However, there is no strong proof that AI is the sole reason for the rise in unemployment; the evidence remains inconclusive. Another hypothesis is that, like the Industrial Revolution, AI may cause labour displacement at first, but it may also create massive amounts of value elsewhere in the economy, spawning totally new businesses. However, if AI is directly promoting workforce abundance, then empirical law may not apply [25]. There is no economic law stating that new technology always creates jobs [26]. However, based on previous trends, AI may not reduce overall employment due to the emergence of new occupations.

The question of impact thus becomes one of wages rather than jobs. When a machine can perform a worker's task, the worker's pay eventually lowers to match the machine's cost. New occupations may develop, but machines will learn to complete them more quickly and cheaply. Initial simulations demonstrate that, in the short term, because automation is initially focused on activities rather than employment, salaries rise and all growth benefits accrue to labour. However, once a certain threshold is reached, the availability of capital and low labour demand cause wages to collapse, and returns are primarily determined by capital. While items get cheaper, earnings are dramatically lowered [27].

Sam Altman knew this way back in 2021 [28]. His response, like most others, has been to disperse capital and share equity among all citizens. A universal basic income based on companies that drive AI progress, with all residents being default shareholders. When work is devalued, the government must seek capital taxation from enterprises as well as capital accumulation by AI (as in many present rentier states [29]). While this strategy does help with wealth distribution and inequality, it overlooks a critical element. As previously said, when governments and firms are no longer incentivised to rely on income tax revenue or face a decrease in labour demand, the entire social contract breaks down.

Powerful actors are no longer motivated by personal preferences but rather by the need to maintain corporate dominance. States will be incentivised to withdraw public support, while businesses may be incentivised to fire and never hire new employees. This may not occur immediately, but rather gradually, as AI adoption increases [30]. People may be wealthy as a result of AI-enabled wealth distribution, but they may eventually be reduced to mere viewers of the economy, playing on a large scale.

### States, Military and Politics

When we consider the full scope of our political representations, the direct replacement and influence of AI may be slow. This would be the least affected area, because people generally want key individual representations, voting, and democratic actions to continue, and politicians get to set the standards for what is allowed. While people still appear to be at the helm, many decisions will gradually be aided by AI, beginning with subtle changes that have significant long-term effects. This will be due to growing AI deployment at multiple levels within government, driven by geopolitical competition, efficiency, and effective control.

We've already seen the DOGE (Department of Government Efficiency) moment, in which essential government functions were split down in the name of efficiency, and the majority of those redundant judgments can eventually be taken by AI [31]. Much of it is already being done; in the United States, studies show that 90% of federal agencies use AI for various tasks [32]. AI now plays an important role in policymaking and the legal system by generating and analysing legal documents; in the future, it may have a role in legislation, interpreting laws, and even making judicial decisions. Politicians may seek AI assistance on what laws to pass, how to create legislation, or what the law itself is.

While enhancing efficiency and using AI may be good in the long run, it will gradually reduce human participation and discretion in legislative and judicial institutions. The key factor is that it threatens greater disassociation and alienation of the branches of government from common public interests. As the formation and interpretation of laws get more complicated, humans may find it increasingly difficult to deal directly with legislation and the legal system. Humans may keep sovereignty and vote on their choices, but much of the law and governance may be dictated by AI systems that are disconnected from citizens [33].

Bureaucracies tend to be gradually mechanised, with a significant rise in control and monitoring, which might clearly lead to effective power consolidation for those at the top. Power concentration becomes substantially easier when a small group of people effectively controls the majority of the government's functions, and this power is effectively secured by AI systems [34]. The AI-powered security infrastructure would have extraordinary predictive and preventive capabilities for crime and civil unrest. We are already witnessing this. The present Department of War has already initiated an AI Acceleration strategy to quickly integrate AI into the military to maintain superiority, disregarding safety hazards [35]. High-stakes AI-based military equipment has already been utilised in the recent battle between Russia and Ukraine, as well as the massacre in Gaza [36].

### Culture and Society

Over the last century, technology has had a significant impact on how society interacts and communicates, as well as the transmission of culture. Television, the internet, and, most recently, social media have all influenced our political beliefs, perception of the world, and self-image. Previous technologies were always tools for facilitating human cultural participation, and humans remained indispensable. However, as we can see, social media, in particular, has gone above and beyond in altering people's opinions, increasing polarisation, placing a strong emphasis on virality rather than factual information, information overstimulation, and rapid information dissemination around the world [37]. The Social Networks from Facebook to X largely overall drive what kind of opinions spread, what virals collectively — narrative shaping truth and virality and attention becoming currency. Politics has also largely been affected, with the world becoming a stage and diplomacy largely broken down, tweets becoming global policies and actors like Trump taking control of and shaping the narrative [38].

The widespread usage of AI will continue to drive these trends at an unprecedented rate. Human hosts have always been essential to the survival and spread of cultural varieties. At the moment, AI is inextricably linked to human cultural production and distribution, not as a passive instrument, but as an extraordinarily active shaper of how humans create and communicate [39]. It already has an impact on the creative process in numerous forms, such as music, photos, stories, essays, and so on. AI songs have broken Billboard top 100 records [40], and they have recently begun to actively participate in human discourse. Bots have already entered every nook and crevice of the internet, lending credence to the widely believed 'Dead Internet theory', which argues that the internet has become largely devoid of human activity [41]. AI Agents like Moltbots currently have an active social media platform to interact and communicate with each other, with humans being the passive observers. While this might be an experiment, with a gradual increase in capabilities, there might be a growing share of communication between AIs participating in culture independently.

But how do the phenomena discussed fundamentally disempower humans? Here, we can take a deeper look at how disempowerment works.

As defined by a recent paper by Anthropic: A human is situationally disempowered to the extent that: "1. their beliefs about reality are inaccurate; 2. their value judgments are inauthentic to their values; 3. their actions are misaligned with their values" [42].

Real disempowerment patterns are already commonly noticed in real-world LLM usage; by analysing people's conversations with Claude in a privacy-preserving manner, researchers discovered that the above disempowerment potential appears to be growing. The reality distortion potential, value judgment distortion, and action distortion potential have already received high ratings, with the potential to harm one in every thousand people. Severe examples of these potentials include AI validating delusional notions (e.g., "you're right about the government plot") (reality distortion), systematic outsourcing of moral assessment to AI (value judgment distortion), and decision and action outsourcing across domains [42].

AI is becoming more capable of performing longer-duration tasks and is emotionally intelligent, implying the increasing rate of disempowerment. Relationships and lifestyle already have the highest rate of disempowerment potential, followed by society and culture.

Humans will be increasingly interacting with culture through content curated, processed, and tailored by AI intermediaries [43]. Meanwhile, AI systems may generate the majority of cultural artefacts, ranging from entertainment media to instructive content, albeit with a focus on human consumption. This consequence is not obviously negative in and of itself, but it would reduce humans' ability to guide cultural evolution. Furthermore, there is a high concern that the growing impact of AI will lead to an increase in human banality. With a decrease in individual cognitive thinking and reasoning, which is susceptible to manipulation by these systems, an increase in thoughtlessness may lead to more effective control by powerful individuals and evils, as Arendt observed in her work *Banality of Evil* with Eichmann and Nazi Germany [44].

---

## 3. The Disempowered Future — Open Questions for Change

When we continue to lean toward automation incentives and gradual disempowerment in various spheres, it might be hard to envision a future of absolute disempowerment. From various angles, we may observe humans becoming functionally useless in the production of culture, involvement in politics, and economic activity. Yes, the economy can be driven solely by machines, as Korinek points out, echoing Lincoln: an economy of, by, and for machines [45].

The economy will no longer require the presence of humans. We might end up in a world as portrayed by Rudolf Laine, in a Disneyland without children [46]. The fact that this threat is not limited to a single domain or field makes it even more concerning. We investigated erosion from the perspectives of economy, government, and society, but as Jan and others pointed out [47], misalignment in one of these realms from humans, beginning with a goal to pursue the benefits of AI, may gradually reinforce erosion across all frontiers. The burden overall then shifts towards us in maintaining human influence between different social systems. There are a few who advocate leaving the problem of disempowerment to a future, more sophisticated, more allied AI. This is a logical strawman that maintains humans in charge by doing what the AIs instruct them to [48]. There is a high need right now to rethink our entire institutions and political structure, as pointed out by many.

Existing institutions and infrastructures have considerable problems adequately meeting fundamental societal needs and basic human rights, owing to their profit-making tendencies and complex geopolitical scenarios. The rules-based world order has virtually broken down, and countries are developing their own future policies [49]. There is a high consensus that there is a need for new methods of governance and strengthening of our institutions, making them more resilient to face geopolitical uncertainty and the era of AGI. But when is the ideal time to make that change? Gradual disempowerment in a complex problem involving larger complex systems [50], since by the time we have superintelligent AI, the current institutions that developed it will have been infected by weaker AIs, reducing human significance and changing the incentive landscape [51]. The vision of a positive world is currently hazy, necessitating a great deal of forecasting. There are several unanswered questions about constructing a sociotechnical system geared largely toward human well-being.

This brings me to the subject of influencing the trajectory of technology itself. In Vitalik Buterin's essay, he rejects the notion that technology is inexorably propelling us toward catastrophe or paradise and that all we have control over is the rate of growth. We ultimately create the technology that shapes us and the institutional systems that govern us. For technologies to shape and redirect incentives away from eventual disempowerment and toward empowerment, they need to ensure humanity's active participation and voice in the economy and government, reduce inequality and power concentration, strengthen our institutions, and preserve people's ability to design and evolve their own future. This raises the question: Are there sociotechnological solutions for human empowerment? Do we need to rethink what it means to be human to keep up with AI? In Part II of this project, I'll try to grapple with and explore solutions to these concerns, focusing on sociotechnological alternatives for gradual disempowerment.

---

<details>
<summary>Full Bibliography (51 references)</summary>

"1.1: Overview of Catastrophic AI Risks | AI Safety, Ethics, and Society Textbook," n.d. https://www.aisafetybook.com/textbook/overview-of-catastrophic-ai-risks.

"2.10 Growth: Escaping the Malthusian Trap," n.d. https://books.core-econ.org/the-economy/microeconomics/02-technology-incentives-10-malthusian-trap.html.

"5.1: Complex Systems | AI Safety, Ethics, and Society Textbook," n.d. https://www.aisafetybook.com/textbook/complex-systems.

Bajarin, Tim. "Generative AI's Unprecedented Adoption Cycle." *Forbes*, July 22, 2025. https://forbes.com/sites/timbajarin/2025/07/22/generative-ais-unprecedented-adoption-cycle/.

Cheng, Deric. "Forging a New AGI Social Contract." *Windfall Trust* (blog), April 9, 2025. https://windfalltrust.substack.com/p/forging-a-new-agi-social-contract.

"Companies Replaced Entry-Level Workers with AI. Now They Are Paying the Price," n.d. https://www.fastcompany.com/91483431/companies-replaced-entry-level-workers-with-ai.

The Intelligence Curse. "Defining the Intelligence Curse - the Intelligence Curse," n.d. https://intelligence-curse.ai/defining/.

"Disempowerment Patterns in Real-World AI Usage," n.d. https://www.anthropic.com/research/disempowerment-patterns.

"Economy | the 2025 AI Index Report | Stanford HAI," n.d. https://hai.stanford.edu/ai-index/2025-ai-index-report/economy.

The Budget Lab at Yale. "Evaluating the Impact of AI on the Labour Market: September CPS Update," n.d. https://budgetlab.yale.edu/research/evaluating-impact-ai-labor-market-september-cps-update.

Ifri. "From Ukraine to Gaza: Military Uses of Artificial Intelligence," October 9, 2024. http://www.ifri.org/en/articles-politique-etrangere/politique-etrangere/ukraine-gaza-military-uses-artificial-intelligence.

"Gradual Disempowerment," n.d. https://gradual-disempowerment.ai/.

Hertog, Steffen. "Defying the Resource Curse: Explaining Successful State-Owned Enterprises in Rentier States." *World Politics* 62, no. 2 (March 23, 2010): 261–301. https://doi.org/10.1017/s0043887110000055.

Ikeda, Shinnosuke. "Inconsistent Advice by ChatGPT Influences Decision Making in Various Areas." *Scientific Reports* 14, no. 1 (July 10, 2024): 15876. https://doi.org/10.1038/s41598-024-66821-4.

James, Rhiannon. "Labour MPs Accused of Using ChatGPT to Write Speeches." *The Independent*, September 9, 2025. https://www.independent.co.uk/news/uk/home-news/labour-mp-ai-chat-gpt-speeches-tugendhat-b2823339.html.

Jan_Kulveit. "Gradual Disempowerment, Shell Games and Flinches," n.d. https://www.lesswrong.com/posts/a6FKqvdf6XjFpvKEb/gradual-disempowerment-shell-games-and-flinches.

Jan_Kulveit, David Duvenaud, and Raymond Douglas. "The Economics of Transformative AI," n.d. https://www.lesswrong.com/posts/epFKhn24trRP2cs3k/the-economics-of-transformative-ai.

Kamarck, Elaine. "How Will We Know if DOGE Is Succeeding?" *Brookings*, June 18, 2025. https://www.brookings.edu/articles/how-will-we-know-if-doge-is-succeeding/.

Kelly, Jim. "Research Shows Nearly 90% of U.S. Government Agencies Use AI." *Google Cloud Blog*, January 13, 2026. https://cloud.google.com/blog/topics/public-sector/new-google-public-sector-research-shows-that-nearly-90-of-federal-agencies-are-already-using-ai.

Kochan, Thomas A., and Lee Dyer. *Shaping the Future of Work: A Handbook for Action and a New Social Contract*, 2017. https://openlibrary.org/books/OL29553572M/Shaping_the_Future_of_Work_-_a_Handbook_for_Action_and_a_New_Social_Contract.

Korinek, Anton, and Joseph E. Stiglitz. "Artificial Intelligence and Its Implications for Income Distribution and Unemployment." In *Working Paper Series*, 349–90, 2019. https://doi.org/10.7208/chicago/9780226613475.003.0014.

Korinek, Anton, and Donghyun Suh. "Scenarios for the Transition to AGI," March 1, 2024. https://doi.org/10.3386/w32255.

L, L Rudolf. "A Disneyland Without Children," n.d. https://www.lesswrong.com/posts/pk9mofif2jWbc6Tv3/fiction-a-disneyland-without-children.

"Mark Carney Davos Special Address," n.d. https://www.weforum.org/stories/2026/01/davos-2026-special-address-by-mark-carney-prime-minister-of-canada/.

Money & Macro Media, Grotehondstraat 44, 2018 Antwerp, Belgium. "Why You Cannot Find a Job Right Now," December 2, 2025. https://www.moneymacro.rocks/2025-12-02-job-crisis/.

"Moore's Law for Everything," n.d. https://moores.samaltman.com/.

Olaniran, Bolane, and Indi Williams. "Social Media Effects: Hijacking Democracy and Civility in Civic Engagement." In *Rhetoric, Politics and Society*, 77–94, 2020. https://doi.org/10.1007/978-3-030-36525-7_5.

Paoli, Nino. "Deloitte Was Caught Using AI in $290,000 Report to Help the Australian Government Crack Down on Welfare After a Researcher Flagged Hallucinations." *Fortune*, October 7, 2025. https://fortune.com/2025/10/07/deloitte-ai-australia-government-report-hallucinations-technology-290000-refund/.

Paulfchristiano. "What Failure Looks Like," n.d. https://www.lesswrong.com/posts/HBxe6wdjxK239zajf/what-failure-looks-like.

Open AI. "Planning for AGI and Beyond," n.d. https://openai.com/index/planning-for-agi-and-beyond/.

Forethought. "Preparing for the Intelligence Explosion," n.d. https://www.forethought.org/research/preparing-for-the-intelligence-explosion.

Schiffer, Zoë. "Here's What Mark Zuckerberg Is Offering Top AI Talent." *WIRED*, July 1, 2025. https://www.wired.com/story/mark-zuckerberg-meta-offer-top-ai-talent-300-million/.

The Intelligence Curse. "Shaping the Social Contract - the Intelligence Curse," n.d. https://intelligence-curse.ai/shaping/.

Stanford Digital Economy Lab. "Canaries in the Coal Mine? Six Facts About the Recent Employment Effects of Artificial Intelligence," January 15, 2026. https://digitaleconomy.stanford.edu/publication/canaries-in-the-coal-mine-six-facts-about-the-recent-employment-effects-of-artificial-intelligence/.

Sky News. "Universal Credit Claimants Soar by Over a Million in a Year, New Figures Show," November 12, 2025. https://news.sky.com/story/universal-credit-claimants-soar-by-over-a-million-in-a-year-new-figuresshow-13468726.

Sugihartono, Sekarsari. "The Power of Social Media to Influence Political Views and Geopolitical Issues: TikTok, X and Instagram." *Modern Diplomacy*, September 19, 2024. https://moderndiplomacy.eu/2024/09/19/the-power-of-social-media-to-influence-political-views-and-geopolitical-issues-tiktok-x-and-instagram/.

TRADING ECONOMICS. "United States Unemployment Rate," n.d. https://tradingeconomics.com/united-states/unemployment-rate.

US Department of War. "War Department Launches AI Acceleration Strategy to Secure American Military AI Dominance," January 12, 2026. https://www.war.gov/News/Releases/Release/Article/4376420/war-department-launches-ai-acceleration-strategy-to-secure-american-military-ai/.

New York Times. "What if Labour Becomes Unnecessary," February 4, 2026. https://www.nytimes.com/2026/02/04/opinion/ai-jobs-employment-industry.html.

White, Thomas. "What Did Hannah Arendt Really Mean by the Banality of Evil?" *Aeon*, November 29, 2024. https://aeon.co/ideas/what-did-hannah-arendt-really-mean-by-the-banality-of-evil.

Axios. "White-Collar Blood Bath," n.d. https://www.axios.com/2025/05/28/ai-jobs-white-collar-unemployment-anthropic.

Wikipedia contributors. "Dead Internet Theory - Wikipedia," February 4, 2026. https://en.wikipedia.org/wiki/Dead_Internet_theory.

Wiseman, Jack, and Duncan McClements. "How Much Economic Growth From AI Should We Expect, How Soon?" *Inference* (blog), January 17, 2025. https://inferencemagazine.substack.com/p/how-much-economic-growth-from-ai.

Zellner, Xander. "How Many AI Artists Have Debuted on Billboard's Charts?" *Billboard*, November 12, 2025. https://www.billboard.com/lists/ai-artists-on-billboard-charts/.

Forethought. "AI-Enabled Coups: How a Small Group Could Use AI to Seize Power," n.d. https://www.forethought.org/research/ai-enabled-coups-how-a-small-group-could-use-ai-to-seize-power.

</details>

---

## References

[1] Ikeda, Shinnosuke. "Inconsistent Advice by ChatGPT Influences Decision Making in Various Areas." *Scientific Reports* 14, no. 1 (July 10, 2024): 15876. https://doi.org/10.1038/s41598-024-66821-4.

[2] James, Rhiannon. "Labour MPs Accused of Using ChatGPT to Write Speeches." *The Independent*, September 9, 2025. https://www.independent.co.uk/news/uk/home-news/labour-mp-ai-chat-gpt-speeches-tugendhat-b2823339.html.

[3] Paoli, Nino. "Deloitte Was Caught Using AI in $290,000 Report." *Fortune*, October 7, 2025. https://fortune.com/2025/10/07/deloitte-ai-australia-government-report-hallucinations-technology-290000-refund/.

[4] Stanford Digital Economy Lab. "Canaries in the Coal Mine? Six Facts About the Recent Employment Effects of Artificial Intelligence," January 15, 2026. https://digitaleconomy.stanford.edu/publication/canaries-in-the-coal-mine-six-facts-about-the-recent-employment-effects-of-artificial-intelligence/.

[5] Sky News. "Universal Credit Claimants Soar by Over a Million in a Year," November 12, 2025. https://news.sky.com/story/universal-credit-claimants-soar-by-over-a-million-in-a-year-new-figuresshow-13468726.

[6] Open AI. "Planning for AGI and Beyond," n.d. https://openai.com/index/planning-for-agi-and-beyond/.

[7] Hendrycks, Dan. *Introduction to AI Safety, Ethics and Society.* "1.1: Overview of Catastrophic AI Risks." https://www.aisafetybook.com/textbook/overview-of-catastrophic-ai-risks.

[8] Drago, Luke, et al. "The Intelligence Curse." https://intelligence-curse.ai/.

[9] Kochan, Thomas A., and Lee Dyer. *Shaping the Future of Work: A Handbook for Action and a New Social Contract*, 2017. https://openlibrary.org/books/OL29553572M/Shaping_the_Future_of_Work_-_a_Handbook_for_Action_and_a_New_Social_Contract.

[10] "2.10 Growth: Escaping the Malthusian Trap," n.d. https://books.core-econ.org/the-economy/microeconomics/02-technology-incentives-10-malthusian-trap.html.

[11] "2.10 Growth: Escaping the Malthusian Trap," n.d. https://books.core-econ.org/the-economy/microeconomics/02-technology-incentives-10-malthusian-trap.html.

[12] Jan_Kulveit, David Duvenaud, and Raymond Douglas. "Gradual Disempowerment." Misaligned States. https://gradual-disempowerment.ai/.

[13] Schiffer, Zoë. "Here's What Mark Zuckerberg Is Offering Top AI Talent." *WIRED*, July 1, 2025. https://www.wired.com/story/mark-zuckerberg-meta-offer-top-ai-talent-300-million/.

[14] Hertog, Steffen. "Defying the Resource Curse: Explaining Successful State-Owned Enterprises in Rentier States." *World Politics* 62, no. 2 (March 23, 2010): 261–301. https://doi.org/10.1017/s0043887110000055.

[15] The Intelligence Curse. "Defining the Intelligence Curse," n.d. https://intelligence-curse.ai/defining/.

[16] "Economy | the 2025 AI Index Report | Stanford HAI," n.d. https://hai.stanford.edu/ai-index/2025-ai-index-report/economy.

[17] Bajarin, Tim. "Generative AI's Unprecedented Adoption Cycle." *Forbes*, July 22, 2025. https://forbes.com/sites/timbajarin/2025/07/22/generative-ais-unprecedented-adoption-cycle/.

[18] Jan_Kulveit, David Duvenaud, and Raymond Douglas. "The Economics of Transformative AI," n.d. https://www.lesswrong.com/posts/epFKhn24trRP2cs3k/the-economics-of-transformative-ai.

[19] Jan_Kulveit, David Duvenaud, and Raymond Douglas. "The Economics of Transformative AI," n.d. https://www.lesswrong.com/posts/epFKhn24trRP2cs3k/the-economics-of-transformative-ai.

[20] Forethought. "Preparing for the Intelligence Explosion," n.d. https://www.forethought.org/research/preparing-for-the-intelligence-explosion.

[21] Drago, Luke, et al. "The Intelligence Curse." https://intelligence-curse.ai/.

[22] Axios. "White-Collar Blood Bath," n.d. https://www.axios.com/2025/05/28/ai-jobs-white-collar-unemployment-anthropic.

[23] TRADING ECONOMICS. "United States Unemployment Rate," n.d. https://tradingeconomics.com/united-states/unemployment-rate.

[24] Money & Macro Media. "Why You Cannot Find a Job Right Now," December 2, 2025. https://www.moneymacro.rocks/2025-12-02-job-crisis/.

[25] Stanford Digital Economy Lab. "Canaries in the Coal Mine? Six Facts About the Recent Employment Effects of Artificial Intelligence," January 15, 2026. https://digitaleconomy.stanford.edu/publication/canaries-in-the-coal-mine-six-facts-about-the-recent-employment-effects-of-artificial-intelligence/.

[26] Jan_Kulveit, David Duvenaud, and Raymond Douglas. "The Economics of Transformative AI," n.d. https://www.lesswrong.com/posts/epFKhn24trRP2cs3k/the-economics-of-transformative-ai.

[27] Korinek, Anton. "What if Labour Becomes Unnecessary." *New York Times*, February 4, 2026. https://www.nytimes.com/2026/02/04/opinion/ai-jobs-employment-industry.html.

[28] Korinek, Anton, and Joseph E. Stiglitz. "Artificial Intelligence and Its Implications for Income Distribution and Unemployment." In *Working Paper Series*, 349–90, 2019. https://doi.org/10.7208/chicago/9780226613475.003.0014.

[29] Altman, Sam. "Moore's Law for Everything," n.d. https://moores.samaltman.com/.

[30] The Intelligence Curse. "Shaping the Social Contract," n.d. https://intelligence-curse.ai/shaping/.

[31] Kamarck, Elaine. "How Will We Know if DOGE Is Succeeding?" *Brookings*, June 18, 2025. https://www.brookings.edu/articles/how-will-we-know-if-doge-is-succeeding/.

[32] Kelly, Jim. "Research Shows Nearly 90% of U.S. Government Agencies Use AI." *Google Cloud Blog*, January 13, 2026. https://cloud.google.com/blog/topics/public-sector/new-google-public-sector-research-shows-that-nearly-90-of-federal-agencies-are-already-using-ai.

[33] Jan_Kulveit, David Duvenaud, and Raymond Douglas. "Gradual Disempowerment." Misaligned States. https://gradual-disempowerment.ai/.

[34] Forethought. "AI-Enabled Coups: How a Small Group Could Use AI to Seize Power," n.d. https://www.forethought.org/research/ai-enabled-coups-how-a-small-group-could-use-ai-to-seize-power.

[35] US Department of War. "War Department Launches AI Acceleration Strategy to Secure American Military AI Dominance," January 12, 2026. https://www.war.gov/News/Releases/Release/Article/4376420/war-department-launches-ai-acceleration-strategy-to-secure-american-military-ai/.

[36] Ifri. "From Ukraine to Gaza: Military Uses of Artificial Intelligence," October 9, 2024. http://www.ifri.org/en/articles-politique-etrangere/politique-etrangere/ukraine-gaza-military-uses-artificial-intelligence.

[37] Olaniran, Bolane, and Indi Williams. "Social Media Effects: Hijacking Democracy and Civility in Civic Engagement." In *Rhetoric, Politics and Society*, 77–94, 2020. https://doi.org/10.1007/978-3-030-36525-7_5.

[38] Sugihartono, Sekarsari. "The Power of Social Media to Influence Political Views and Geopolitical Issues: TikTok, X and Instagram." *Modern Diplomacy*, September 19, 2024. https://moderndiplomacy.eu/2024/09/19/the-power-of-social-media-to-influence-political-views-and-geopolitical-issues-tiktok-x-and-instagram/.

[39] Jan_Kulveit, David Duvenaud, and Raymond Douglas. "Gradual Disempowerment." Misaligned Culture. https://gradual-disempowerment.ai/.

[40] Zellner, Xander. "How Many AI Artists Have Debuted on Billboard's Charts?" *Billboard*, November 12, 2025. https://www.billboard.com/lists/ai-artists-on-billboard-charts/.

[41] Wikipedia contributors. "Dead Internet Theory," February 4, 2026. https://en.wikipedia.org/wiki/Dead_Internet_theory.

[42] "Disempowerment Patterns in Real-World AI Usage," n.d. https://www.anthropic.com/research/disempowerment-patterns.

[43] Jan_Kulveit, David Duvenaud, and Raymond Douglas. "Gradual Disempowerment." Misaligned Culture. https://gradual-disempowerment.ai/.

[44] White, Thomas. "What Did Hannah Arendt Really Mean by the Banality of Evil?" *Aeon*, November 29, 2024. https://aeon.co/ideas/what-did-hannah-arendt-really-mean-by-the-banality-of-evil.

[45] Jan_Kulveit, David Duvenaud, and Raymond Douglas. "The Economics of Transformative AI," n.d. https://www.lesswrong.com/posts/epFKhn24trRP2cs3k/the-economics-of-transformative-ai.

[46] L, Rudolf. "A Disneyland Without Children," n.d. https://www.lesswrong.com/posts/pk9mofif2jWbc6Tv3/fiction-a-disneyland-without-children.

[47] Jan_Kulveit, David Duvenaud, and Raymond Douglas. "Gradual Disempowerment." Mutual Reinforcement. https://gradual-disempowerment.ai/.

[48] Jan_Kulveit. "Gradual Disempowerment, Shell Games and Flinches," n.d. https://www.lesswrong.com/posts/a6FKqvdf6XjFpvKEb/gradual-disempowerment-shell-games-and-flinches.

[49] "Mark Carney Davos Special Address," n.d. https://www.weforum.org/stories/2026/01/davos-2026-special-address-by-mark-carney-prime-minister-of-canada/.

[50] "5.1: Complex Systems | AI Safety, Ethics, and Society Textbook," n.d. https://www.aisafetybook.com/textbook/complex-systems.

[51] Jan_Kulveit. "Gradual Disempowerment, Shell Games and Flinches," n.d. https://www.lesswrong.com/posts/a6FKqvdf6XjFpvKEb/gradual-disempowerment-shell-games-and-flinches.
